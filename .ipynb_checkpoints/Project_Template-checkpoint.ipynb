{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Template (Notebook Version)\n",
    "\n",
    "Â©2018 Created by Yiming Peng and Bing Xue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "### Description:\n",
    "The train.py is to build your CNN model, train the model, and save it for later evaluation(marking)\n",
    "This is just a simple template, you feel free to change it according to your own style.\n",
    "However, you must make sure:\n",
    "1. Your own model is saved to the directory \"model\" and named as \"model.h5\"\n",
    "2. The \"test.py\" must work properly with your model, this will be used by tutors for marking.\n",
    "3. If you have added any extra pre-processing steps, please make sure you also implement them in \"test.py\" so that they can later be applied to test images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "# SEED\n",
    "SEED = 309\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "#tf.set_random_seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_model():\n",
    "    \"\"\"\n",
    "    Construct the CNN model.\n",
    "    ***\n",
    "        Please add your model implementation here, and don't forget compile the model\n",
    "        E.g., model.compile(loss='categorical_crossentropy',\n",
    "                            optimizer='sgd',\n",
    "                            metrics=['accuracy'])\n",
    "        NOTE, You must include 'accuracy' in as one of your metrics, which will be used for marking later.\n",
    "    ***\n",
    "    :return: model: the initial CNN model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=64, activation='relu', input_dim=100))\n",
    "    model.add(Dense(units=10, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    \"\"\"\n",
    "    Train the CNN model\n",
    "    ***\n",
    "        Please add your training implementation here, including pre-processing and training\n",
    "    ***\n",
    "    :param model: the initial CNN model\n",
    "    :return:model:   the trained CNN model\n",
    "    \"\"\"\n",
    "    # Add your code here\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    \"\"\"\n",
    "    Save the keras model for later evaluation\n",
    "    :param model: the trained CNN model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # ***\n",
    "    #   Please remove the comment to enable model save.\n",
    "    #   However, it will overwrite the baseline model we provided.\n",
    "    # ***\n",
    "    #model.save(\"model/model.h5\")\n",
    "    print(\"Model Saved Successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run your train\n",
    "Identical to the main in train.py of the template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 7,114\n",
      "Trainable params: 7,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model Saved Successfully.\n"
     ]
    }
   ],
   "source": [
    "model = construct_model()\n",
    "model = train_model(model)\n",
    "save_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "### Description:\n",
    "The test.py is to evaluate your model on the test images.\n",
    "\n",
    "***IMPORTANT***\n",
    "\n",
    "After you test here with the notebook, you have to make the test.py work properly. Your final submission should include the test.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "# Import modules for test\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from tensorflow.python.keras.preprocessing.image import img_to_array\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Import related functions from test.py\n",
    "from test import load_images, convert_img_to_array, preprocess_data, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y has 0 samples: array([], dtype=float64)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-8-6e57b06af99b>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;31m# Convert images to numpy arrays (images are normalized with constant 255.0), and binarize categorical labels\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 13\u001B[1;33m \u001B[0mX_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconvert_img_to_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;31m# Preprocess data.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\DeepConvolutionalNeuralNetwork\\test.py\u001B[0m in \u001B[0;36mconvert_img_to_array\u001B[1;34m(images, labels)\u001B[0m\n\u001B[0;32m     73\u001B[0m     \u001B[1;31m# Binarize the labels\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     74\u001B[0m     \u001B[0mlb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mLabelBinarizer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 75\u001B[1;33m     \u001B[0my_test\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlb\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     76\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     77\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mX_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\matt\\pycharmprojects\\deepconvolutionalneuralnetwork\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001B[0m in \u001B[0;36mfit_transform\u001B[1;34m(self, y)\u001B[0m\n\u001B[0;32m    458\u001B[0m             \u001B[0mShape\u001B[0m \u001B[0mwill\u001B[0m \u001B[0mbe\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mn_samples\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mbinary\u001B[0m \u001B[0mproblems\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    459\u001B[0m         \"\"\"\n\u001B[1;32m--> 460\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    461\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    462\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\matt\\pycharmprojects\\deepconvolutionalneuralnetwork\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, y)\u001B[0m\n\u001B[0;32m    432\u001B[0m                              \"label binarization\")\n\u001B[0;32m    433\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0m_num_samples\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 434\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'y has 0 samples: %r'\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    435\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    436\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msparse_input_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0missparse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: y has 0 samples: array([], dtype=float64)"
     ]
    }
   ],
   "source": [
    "# This is just like the main in test.py, but here, you need to specify your test images directory.\n",
    "\n",
    "# Test folder \"\"\n",
    "test_data_dir = \"data/test\"\n",
    "\n",
    "# Image size, please define according to your settings when training your model.\n",
    "image_size = (64, 64)\n",
    "\n",
    "# Load images\n",
    "images, labels = load_images(test_data_dir, image_size)\n",
    "\n",
    "# Convert images to numpy arrays (images are normalized with constant 255.0), and binarize categorical labels\n",
    "X_test, y_test = convert_img_to_array(images, labels)\n",
    "\n",
    "# Preprocess data.\n",
    "# ***If you have any preprocess, please re-implement the function \"preprocess_data\"; otherwise, you can skip this***\n",
    "X_test = preprocess_data(X_test)\n",
    "\n",
    "X_test = np.random.rand(15, 64)\n",
    "# Evaluation, please make sure that your training model uses \"accuracy\" as metrics, i.e., metrics=['accuracy']\n",
    "loss, accuracy = evaluate(X_test, y_test)\n",
    "print(\"loss={}, accuracy={}\".format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}