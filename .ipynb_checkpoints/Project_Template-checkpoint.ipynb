{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Template (Notebook Version)\n",
    "\n",
    "Â©2018 Created by Yiming Peng and Bing Xue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "### Description:\n",
    "The train.py is to build your CNN model, train the model, and save it for later evaluation(marking)\n",
    "This is just a simple template, you feel free to change it according to your own style.\n",
    "However, you must make sure:\n",
    "1. Your own model is saved to the directory \"model\" and named as \"model.h5\"\n",
    "2. The \"test.py\" must work properly with your model, this will be used by tutors for marking.\n",
    "3. If you have added any extra pre-processing steps, please make sure you also implement them in \"test.py\" so that they can later be applied to test images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "# SEED\n",
    "SEED = 309\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "#tf.set_random_seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_model():\n",
    "    \"\"\"\n",
    "    Construct the CNN model.\n",
    "    ***\n",
    "        Please add your model implementation here, and don't forget compile the model\n",
    "        E.g., model.compile(loss='categorical_crossentropy',\n",
    "                            optimizer='sgd',\n",
    "                            metrics=['accuracy'])\n",
    "        NOTE, You must include 'accuracy' in as one of your metrics, which will be used for marking later.\n",
    "    ***\n",
    "    :return: model: the initial CNN model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=64, activation='relu', input_dim=100))\n",
    "    model.add(Dense(units=10, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    \"\"\"\n",
    "    Train the CNN model\n",
    "    ***\n",
    "        Please add your training implementation here, including pre-processing and training\n",
    "    ***\n",
    "    :param model: the initial CNN model\n",
    "    :return:model:   the trained CNN model\n",
    "    \"\"\"\n",
    "    # Add your code here\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def save_model(model):\n",
    "    \"\"\"\n",
    "    Save the keras model for later evaluation\n",
    "    :param model: the trained CNN model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # ***\n",
    "    #   Please remove the comment to enable model save.\n",
    "    #   However, it will overwrite the baseline model we provided.\n",
    "    # ***\n",
    "    #model.save(\"model/model.h5\")\n",
    "    print(\"Model Saved Successfully.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Run your train\n",
    "Identical to the main in train.py of the template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 298, 298, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 149, 149, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 147, 147, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 73, 73, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 71, 71, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 78400)             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                5017664   \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 3)                 195       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 5,046,499\n",
      "Trainable params: 5,046,499\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-66-857026ce4caf>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconstruct_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0msave_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-64-bde95a5973e9>\u001B[0m in \u001B[0;36mtrain_model\u001B[1;34m(model)\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[1;33m:\u001B[0m\u001B[1;32mreturn\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m:\u001B[0m   \u001B[0mthe\u001B[0m \u001B[0mtrained\u001B[0m \u001B[0mCNN\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m     \"\"\"\n\u001B[1;32m---> 10\u001B[1;33m     \u001B[0mx_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_training_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m     \u001B[1;31m# TODO validation_split=0.1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m     model.fit(x_train, y_train,\n",
      "\u001B[1;32m<ipython-input-62-3607e480e57c>\u001B[0m in \u001B[0;36mload_training_data\u001B[1;34m()\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[1;31m# Load images\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m     \u001B[0mimages\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_images\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_data_dir\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mimage_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m     \u001B[1;31m# Convert images to numpy arrays (images are normalized with constant 255.0), and binarize categorical labels\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-65-8349c143aee7>\u001B[0m in \u001B[0;36mload_images\u001B[1;34m(test_data_dir, image_size)\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[0mimages_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[0mlabels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m     \u001B[0mimagePaths\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpaths\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlist_images\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_data_dir\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mimagePath\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mimagePaths\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m         \u001B[1;31m# load the image, pre-process it, and store it in the data list\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'paths' is not defined"
     ]
    }
   ],
   "source": [
    "model = construct_model()\n",
    "model = train_model(model)\n",
    "save_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "### Description:\n",
    "The test.py is to evaluate your model on the test images.\n",
    "\n",
    "***IMPORTANT***\n",
    "\n",
    "After you test here with the notebook, you have to make the test.py work properly. Your final submission should include the test.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules for test\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from tensorflow.python.keras.preprocessing.image import img_to_array\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Import related functions from test.py\n",
    "from test import load_images, convert_img_to_array, preprocess_data, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just like the main in test.py, but here, you need to specify your test images directory.\n",
    "\n",
    "# Test folder \"\"\n",
    "test_data_dir = \"data/test\"\n",
    "\n",
    "# Image size, please define according to your settings when training your model.\n",
    "image_size = (64, 64)\n",
    "\n",
    "# Load images\n",
    "images, labels = load_images(test_data_dir, image_size)\n",
    "\n",
    "# Convert images to numpy arrays (images are normalized with constant 255.0), and binarize categorical labels\n",
    "X_test, y_test = convert_img_to_array(images, labels)\n",
    "\n",
    "# Preprocess data.\n",
    "# ***If you have any preprocess, please re-implement the function \"preprocess_data\"; otherwise, you can skip this***\n",
    "X_test = preprocess_data(X_test)\n",
    "\n",
    "X_test = np.random.rand(15, 64)\n",
    "# Evaluation, please make sure that your training model uses \"accuracy\" as metrics, i.e., metrics=['accuracy']\n",
    "loss, accuracy = evaluate(X_test, y_test)\n",
    "print(\"loss={}, accuracy={}\".format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}